{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sincomments_original_ampc_PyG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRnZ9lBg1M9J",
        "outputId": "d9881e01-c75b-40fc-c277-7c34dadf3006"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdd3FLcUBIvx"
      },
      "source": [
        "# !pip uninstall -y torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALSQ0ETd1Lg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcc47ea3-e0ba-4772-f0ff-d66d1634f784"
      },
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "!pip install ogb\n",
        "!pip install rdkit-pypi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 14.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 10.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.1 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.62.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.1.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.0.1)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.10.0+cu111)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=365f05dbc9a2fa070086a6ab91f38f6bea818e1497f79066bb9d209707f9d4c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.2 outdated-0.2.1\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2021.9.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi) (1.19.5)\n",
            "Installing collected packages: rdkit-pypi\n",
            "Successfully installed rdkit-pypi-2021.9.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgLLO3AFsQd2"
      },
      "source": [
        "## Importamos las librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjnN4zfa1Y4F"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# For Dataset generation and visualization\n",
        "from rdkit import Chem\n",
        "# from rdkit.Chem.Draw import IPythonConsole\n",
        "# from rdkit.Chem import Draw\n",
        "# IPythonConsole.ipython_useSVG=True  #< set this to False if you want PNGs instead of SVGs\n",
        "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
        "from ogb.utils.features import atom_to_feature_vector, bond_to_feature_vector\n",
        "\n",
        "# Extras\n",
        "import os.path as osp\n",
        "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from math import sqrt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OP6GRfm0dIo"
      },
      "source": [
        "## Dataset visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNzoFyt6UlWa"
      },
      "source": [
        "csv_path = '/content/drive/MyDrive/GNN/ampc/training_ds.csv'\n",
        "molecules = pd.read_csv(csv_path).sample(10).values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKyETmBkAeSo"
      },
      "source": [
        "## Data Handling of Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brDSnyzp94tM"
      },
      "source": [
        "# Pytorch geometric modules\n",
        "from torch_geometric.data import Data, Dataset, InMemoryDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "\n",
        "class moleculesDS(InMemoryDataset):\n",
        "  def __init__(self, root, csv_path, transform=None, pre_transform=None):\n",
        "    self.csv_path = csv_path\n",
        "    super().__init__(root, transform, pre_transform)\n",
        "    self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return []\n",
        "    \n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    # After preprocesing usinf comment columns\n",
        "    files = 'final_v1.pt'\n",
        "    return files\n",
        "\n",
        "\n",
        "  def download(self):\n",
        "    pass\n",
        "\n",
        "  def process(self):\n",
        "    data_list = []\n",
        "    molecules = pd.read_csv(self.csv_path).values\n",
        "\n",
        "    for smiles, act in molecules:\n",
        "        y = torch.tensor(act, dtype=torch.float32).reshape(-1, 1)\n",
        "        \n",
        "        # Throw molecules in wich molecules can not be obtanined\n",
        "        try:\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "        except:\n",
        "            mol = None\n",
        "        if mol is None:\n",
        "            print('mol is none')\n",
        "            continue\n",
        "\n",
        "        all_node_feats = []\n",
        "        for atom in mol.GetAtoms():\n",
        "            node_feats = atom_to_feature_vector(atom)\n",
        "            all_node_feats.append(node_feats)\n",
        "\n",
        "        all_node_feats = np.asarray(all_node_feats)\n",
        "        x = torch.tensor(all_node_feats, dtype=torch.long).view(-1, 9)\n",
        "\n",
        "        edge_attr = []\n",
        "        edge_index = []\n",
        "        for bond in mol.GetBonds():\n",
        "\n",
        "            bond_feats = bond_to_feature_vector(bond)\n",
        "            edge_attr.append([bond_feats, bond_feats])\n",
        "\n",
        "            i = bond.GetBeginAtomIdx()\n",
        "            j = bond.GetEndAtomIdx()\n",
        "            edge_index += [[i, j], [j, i]]\n",
        "\n",
        "\n",
        "        edge_attr = torch.tensor(edge_attr)\n",
        "        edge_attr = edge_attr.to(torch.long).view(-1, 3)\n",
        "\n",
        "        edge_index = torch.tensor(edge_index)\n",
        "        edge_index = edge_index.t().to(torch.long).view(2, -1)\n",
        "\n",
        "\n",
        "        data = Data(x=x, edge_index=edge_index, edge_attr = edge_attr, y=y.reshape(1, 1), smiles=smiles)\n",
        "\n",
        "        data_list.append(data)\n",
        "\n",
        "    data, slices = self.collate(data_list)\n",
        "    torch.save((data, slices), self.processed_paths[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vxpiAbinpPM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaXlqnUSsWF4"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXc4VCJ2sU2j"
      },
      "source": [
        "from torch_geometric.nn import GATv2Conv, GCNConv\n",
        "from torch_geometric.nn import global_mean_pool, BatchNorm\n",
        "\n",
        "from torch.nn import Sequential, ModuleList, ReLU, Linear, Dropout\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.nn.models import AttentiveFP\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, num_layers, dropout):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "\n",
        "        self.emb = AtomEncoder(hidden_channels)\n",
        "        self.bondemb = BondEncoder(3)\n",
        "\n",
        "        self.AttentiveFP = AttentiveFP(in_channels=hidden_channels, hidden_channels=hidden_channels*10, out_channels=1,\n",
        "                     edge_dim=3, num_layers=num_layers, num_timesteps=1, dropout=dropout)\n",
        "        \n",
        "        \n",
        "    def forward(self, x, edge_index, edge_attr, batch_index):\n",
        "        x = self.emb(x)\n",
        "        edge_attr = self.bondemb(edge_attr)\n",
        "        x = self.AttentiveFP(x, edge_index, edge_attr, batch_index)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxexucmQnlgZ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7-MZEwkOVN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8796cbcd-1595-4ab4-aaef-f76d4b33e6e9"
      },
      "source": [
        "from sklearn.metrics import precision_score, matthews_corrcoef, accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import rdkit.Chem as Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device is: {DEVICE}')\n",
        "\n",
        "\n",
        "def get_metrics(y_true, y_pred):\n",
        "    y_pred = np.rint(y_pred)\n",
        "\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    matthews = matthews_corrcoef(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return precision, matthews, accuracy\n",
        "\n",
        "\n",
        "def training_step(model, x, edge_index, edge_attr, batch_index, y_target, criterion, optimizer):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    h = model(x, edge_index, edge_attr, batch_index)\n",
        "\n",
        "    loss = criterion(h.reshape(-1), y_target.reshape(-1))\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    return float(loss), h\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_step(model, x, edge_index, edge_attr, batch_index, y_target, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    h = model(x, edge_index, edge_attr, batch_index)\n",
        "\n",
        "    loss = criterion(h, y_target)\n",
        "\n",
        "    return float(loss), h\n",
        "\n",
        "\n",
        "def epoch(model, dataloader, criterion, optimizer, training=True):\n",
        "\n",
        "    total_loss = 0\n",
        "    total_examples = 0\n",
        "\n",
        "    y_target_list = []\n",
        "    h_list = []\n",
        "\n",
        "    for data in dataloader:\n",
        "        data = data.to(DEVICE)\n",
        "        y_target = data.y\n",
        "        x, edge_index, edge_attr, batch_index = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "\n",
        "        y_target = y_target.reshape(-1, 1)\n",
        "\n",
        "        if training:\n",
        "            loss, h = training_step(model, x, edge_index, edge_attr, batch_index, y_target, criterion, optimizer)\n",
        "        else:\n",
        "            loss, h = test_step(model, x, edge_index, edge_attr, batch_index, y_target, criterion)\n",
        "\n",
        "        total_loss += loss * len(y_target)\n",
        "        total_examples += len(y_target)\n",
        "\n",
        "        y_target_list.append(y_target)\n",
        "        h_list.append(h)\n",
        "\n",
        "    y_true = torch.cat(y_target_list, dim=0).detach().cpu().numpy()\n",
        "    y_pred = torch.sigmoid(torch.cat(h_list, dim=0)).detach().cpu().numpy()\n",
        "\n",
        "    precision_score, matthews_corrcoef, accuracy = get_metrics(y_true, y_pred)\n",
        "\n",
        "    return total_loss/total_examples, precision_score, matthews_corrcoef, accuracy\n",
        "\n",
        "\n",
        "def training_init(EPOCHS, model, dataloaders, criterion, optimizer):\n",
        "    train_metrics = []\n",
        "    test_metrics = []\n",
        "\n",
        "    train_dataloader, test_dataloader = dataloaders\n",
        "\n",
        "    for e in range(EPOCHS):\n",
        "        train_total_loss, train_precision_score, train_matthews_corrcoef, train_accuracy = epoch(\n",
        "            model, train_dataloader, criterion, optimizer)\n",
        "        train_metrics.append([train_total_loss, train_precision_score, train_matthews_corrcoef, train_accuracy])\n",
        "\n",
        "        test_total_loss, test_precision_score, test_matthews_corrcoef, test_accuracy = epoch(\n",
        "            model, test_dataloader, criterion, optimizer, training=False)\n",
        "        test_metrics.append([test_total_loss, test_precision_score, test_matthews_corrcoef, test_accuracy])\n",
        "\n",
        "        if e % 2 == 0:\n",
        "            print(f'Epoch {e}')\n",
        "            print(f'loss {train_total_loss:.4f} | precision_score {train_precision_score:.4f} | matthews_corrcoef {train_matthews_corrcoef:.4f} | accuracy {train_accuracy:.4f}')\n",
        "            print(f'loss {test_total_loss:.4f} | precision_score {test_precision_score:.4f} | matthews_corrcoef {test_matthews_corrcoef:.4f} | accuracy {test_accuracy:.4f}')\n",
        "            print()\n",
        "\n",
        "    return test_precision_score, (train_metrics, test_metrics)\n",
        "\n",
        "def get_dataset_and_weight(root, file_name, batch_size, shuffle=True):\n",
        "    dataset = moleculesDS(root = root, csv_path = file_name)\n",
        "    loader = DataLoader(dataset, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "    pos_weight = len(dataset.data.y.reshape(-1)) / dataset.data.y.sum()\n",
        "    pos_weight = torch.Tensor([pos_weight])\n",
        "    return loader, pos_weight\n",
        "\n",
        "def get_model_criterion_optimizer(pos_weight, lr, num_layers, dropout):\n",
        "    model = GCN(9, num_layers, dropout)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = 1**-6)\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight = pos_weight)\n",
        "    return model, criterion, optimizer\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device is: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UKs8Eu-OYLu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "56cc2266-4bbd-440d-9d82-e94d3904dfee"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    batch_size_train = 120\n",
        "    batch_size_test = 40\n",
        "\n",
        "    root = '/content/drive/MyDrive/GNN/training'\n",
        "    train_file_name = '/content/drive/MyDrive/ampc_fp_optuna/training_wdec_ds.csv' \n",
        "    train_dataloader, weight = get_dataset_and_weight(\n",
        "        root, train_file_name, batch_size_train, shuffle=True)\n",
        "\n",
        "    root = '/content/drive/MyDrive/GNN/testing'\n",
        "    test_file_name = '/content/drive/MyDrive/ampc_fp_optuna/test_wdec_ds.csv' \n",
        "    test_dataloader, _ = get_dataset_and_weight(\n",
        "        root, test_file_name, batch_size_test, shuffle=False)\n",
        "\n",
        "    num_hidden_layers = 1\n",
        "    dropout = 0.55\n",
        "    lr = 0.0005222696558416456\n",
        "    model, criterion, optimizer = get_model_criterion_optimizer(\n",
        "        weight, lr, num_hidden_layers, dropout)\n",
        "    \n",
        "    # Generate the model.\n",
        "    model = model.to(DEVICE)\n",
        "    criterion = criterion.to(DEVICE)\n",
        "\n",
        "    # Training init\n",
        "    EPOCHS = 40\n",
        "    _, metrics = training_init(EPOCHS, model, [train_dataloader,\n",
        "                  test_dataloader], criterion, optimizer)\n",
        "    \n",
        "    # Metrics unpacking\n",
        "    train_metrics, test_metrics = metrics\n",
        "    train_metrics, test_metrics = np.array(train_metrics), np.array(test_metrics)\n",
        "\n",
        "    train_total_loss, train_precision_score, train_matthews_corrcoef, train_accuracy = train_metrics[:,0], train_metrics[:,1], train_metrics[:,2], train_metrics[:,3]\n",
        "    test_total_loss, test_precision_score, test_matthews_corrcoef, test_accuracy = test_metrics[:,0], test_metrics[:,1], test_metrics[:,2], test_metrics[:,3]\n",
        "\n",
        "    # Taken from matplotlib documentation\n",
        "    #AX1\n",
        "    fig, ax1 = plt.subplots(figsize=(12,10))\n",
        "    #figure(figsize=(18, 16), dpi=300)\n",
        "\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss', color='tab:red')\n",
        "    ax1.tick_params(axis='y', labelcolor='tab:red')\n",
        "\n",
        "    # Loss\n",
        "    t = range(EPOCHS)\n",
        "    ax1.plot(t, train_total_loss, color='tab:red')\n",
        "    ax1.plot(t, test_total_loss, color='chocolate', linestyle='dashed')\n",
        "\n",
        "    # AX2\n",
        "    # Presicion\n",
        "    ax2 = ax1.twinx()  \n",
        "    ax2.set_ylabel('Precision', color='tab:blue')  \n",
        "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
        "\n",
        "    ax2.plot(t, train_precision_score, color='tab:blue')\n",
        "    ax2.plot(t, test_precision_score, color='violet', linestyle='dashed')\n",
        "\n",
        "    fig.tight_layout() \n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "loss 1.8747 | precision_score 0.0411 | matthews_corrcoef 0.0181 | accuracy 0.5372\n",
            "loss 1.2633 | precision_score 0.0651 | matthews_corrcoef 0.0853 | accuracy 0.7945\n",
            "\n",
            "Epoch 2\n",
            "loss 1.4137 | precision_score 0.0396 | matthews_corrcoef 0.0123 | accuracy 0.4658\n",
            "loss 1.2628 | precision_score 0.1429 | matthews_corrcoef 0.1576 | accuracy 0.9202\n",
            "\n",
            "Epoch 4\n",
            "loss 1.3799 | precision_score 0.0395 | matthews_corrcoef 0.0102 | accuracy 0.5399\n",
            "loss 1.2963 | precision_score 0.0350 | matthews_corrcoef 0.0242 | accuracy 0.0890\n",
            "\n",
            "Epoch 6\n",
            "loss 1.3780 | precision_score 0.0391 | matthews_corrcoef 0.0075 | accuracy 0.5783\n",
            "loss 1.2775 | precision_score 0.0405 | matthews_corrcoef 0.0362 | accuracy 0.5083\n",
            "\n",
            "Epoch 8\n",
            "loss 1.3591 | precision_score 0.0396 | matthews_corrcoef 0.0110 | accuracy 0.5250\n",
            "loss 1.2785 | precision_score 0.0651 | matthews_corrcoef 0.0966 | accuracy 0.7578\n",
            "\n",
            "Epoch 10\n",
            "loss 1.3596 | precision_score 0.0390 | matthews_corrcoef 0.0089 | accuracy 0.4685\n",
            "loss 1.2840 | precision_score 0.0573 | matthews_corrcoef 0.0885 | accuracy 0.6826\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-6b3f5b4085e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     _, metrics = training_init(EPOCHS, model, [train_dataloader,\n\u001b[0;32m---> 28\u001b[0;31m                   test_dataloader], criterion, optimizer)\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Metrics unpacking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-184cdaa467a2>\u001b[0m in \u001b[0;36mtraining_init\u001b[0;34m(EPOCHS, model, dataloaders, criterion, optimizer)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         train_total_loss, train_precision_score, train_matthews_corrcoef, train_accuracy = epoch(\n\u001b[0;32m---> 96\u001b[0;31m             model, train_dataloader, criterion, optimizer)\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_precision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_matthews_corrcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-184cdaa467a2>\u001b[0m in \u001b[0;36mepoch\u001b[0;34m(model, dataloader, criterion, optimizer, training)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-184cdaa467a2>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(model, x, edge_index, edge_attr, batch_index, y_target, criterion, optimizer)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2urZIyEpOUM1"
      },
      "source": [
        "---"
      ]
    }
  ]
}